{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('BD Completo.xlsx')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento nos valores faltantes\n",
    "sns.heatmap(dataset.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo o somatório de valores faltantes em todas as colunas\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "\n",
    "# Obtendo nomes das colunas com somatório de valores nulos maior que 200\n",
    "colunas_a_excluir = missing_values_count[missing_values_count > 200].index.tolist()\n",
    "print(len(colunas_a_excluir))\n",
    "print(colunas_a_excluir)\n",
    "colunas_a_excluir = ['EV/EBITDA', 'DPA', 'Dividend Yield', 'Payout', 'Luc. Liq * NR', 'Resultado Bruto', 'Margem Bruta', 'EBIT', 'D&A', 'EBITDA', 'Margem EBITDA', 'Res. Financeiro', 'ROA', 'SSS', 'Patri. Liquido', 'RIF', 'Margem Bancaria', 'Indc. Eficiencia', 'Indc. Basileia', 'PDD', 'PDD/LL', 'Equity Multi.', 'Div Liquida/EBITDA', 'Indice de Cobertura', 'Despesas com juros', 'Custo % da divida', 'IPL', 'FCO', 'FCI', 'FCF', 'FCT', 'FCL', 'FCI/LL', 'CAPEX', 'FCL CAPEX', 'CAPEX/LL', 'CAPEX/FCO', 'Majoritar.']\n",
    "\n",
    "\n",
    "\n",
    "# Excluindo as colunas do DataFrame\n",
    "dataset.drop(labels=colunas_a_excluir, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas as colunas numéricas do DataFrame\n",
    "numeric_columns = dataset.select_dtypes(include=[np.number])\n",
    "\n",
    "# Preenchendo os valores nulos com a média das colunas numéricas\n",
    "dataset[numeric_columns.columns] = numeric_columns.fillna(numeric_columns.mean())\n",
    "\n",
    "# Verificando novamente o somatório de valores nulos em cada coluna\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max.rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['Segmento'] = dataset['Segmento'].apply(corrige_segmento)\n",
    "np.unique(dataset['Segmento'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dataset['Categoria'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrige_categoria(texto):\n",
    "    categoria = ''\n",
    "    if texto == 'crescimento ':\n",
    "        categoria = 'crescimento'\n",
    "    else:\n",
    "        categoria = texto\n",
    "    \n",
    "    return categoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Categoria'] = dataset['Categoria'].apply(corrige_categoria)\n",
    "np.unique(dataset['Categoria'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.countplot(x = dataset['Categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['LPA'] == -806.670000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['LPA'] == 200.660000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['LPA desconctado'] == 160.780000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['Caixa'] == -0.125000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['Caixa'] == 59223.000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['Divida Liquida'] == 199245.000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figura = plt.figure(figsize=(15,20))\n",
    "eixo = figura.gca()\n",
    "dataset.hist(ax=eixo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULANDO A CORRELAÇÃO ENTRE AS COLUNAS\n",
    "# 1 indica correlação perfeita, como uma variável influencia em outra\n",
    "# 1 pode induzir o algoritmo a erros\n",
    "# Correlação negativa indica que uma variavel aumenta se outra diminui\n",
    "# Correlação de um atributo dele com ele mesmo é sempre 1\n",
    "\n",
    "# Seleciona apenas as colunas numéricas\n",
    "numeric_columns = dataset.select_dtypes(include=[float, int])\n",
    "\n",
    "# Remove a coluna 'Situação' se ela existir\n",
    "if 'Situação' in numeric_columns.columns:\n",
    "    numeric_columns = numeric_columns.drop(columns=['Situação'])\n",
    "\n",
    "# Cria o heatmap de correlação\n",
    "plt.figure(figsize=(30, 50))\n",
    "sns.heatmap(numeric_columns.corr(), annot=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Rec. Liquida', 'Caixa'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona apenas as colunas numéricas\n",
    "numeric_columns = dataset.select_dtypes(include=[float, int])\n",
    "\n",
    "# Remove a coluna 'Situação' se ela existir\n",
    "if 'Situação' in numeric_columns.columns:\n",
    "    numeric_columns = numeric_columns.drop(columns=['Situação'])\n",
    "\n",
    "# Cria o heatmap de correlação\n",
    "plt.figure(figsize=(30, 50))\n",
    "sns.heatmap(numeric_columns.corr(), annot=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Divida bruta', 'LPA', 'Caixa.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['At. Circulante', 'Liq. Corrente'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORAM APAGADOS ALGUNS ATRIBUTOS QUE ERAM CALCULADOS POR OUTROS\n",
    "# NOTA-SE QUE A QUANTIDADE DE QUADROS BRANCOS DIMINUIU\n",
    "# INFORMAÇÕES IMPORTANTES PODEM SER TIRADAS DO GRÁFICO ABAIXO, COMO A CORRELAÇÃO NEGATIVA DE LPA DESCONTADO E VPA\n",
    "\n",
    "# Seleciona apenas as colunas numéricas\n",
    "numeric_columns = dataset.select_dtypes(include=[float, int])\n",
    "\n",
    "# Remove a coluna 'Situação' se ela existir\n",
    "if 'Situação' in numeric_columns.columns:\n",
    "    numeric_columns = numeric_columns.drop(columns=['Situação'])\n",
    "\n",
    "# Cria o heatmap de correlação\n",
    "plt.figure(figsize=(30, 50))\n",
    "sns.heatmap(numeric_columns.corr(), annot=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIAVEIS DUMMY\n",
    "# aéreo - 0\n",
    "# turismo - 1\n",
    "# bebidas - 2\n",
    "# 1 0 0\n",
    "# 0 1 0\n",
    "# 0 0 1\n",
    "\n",
    "# SÃO IMPORTANTES PARA PREPARAR OS DADOS PARA ENVIAR AOS ALGORITMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Situação'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empresa = dataset['Empresa']\n",
    "empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = dataset[['Segmento', 'Categoria']]\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "\n",
    "X_cat = onehotencoder.fit_transform(X_cat).toarray()\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Segmento', 'Categoria', 'Situação', 'Empresa'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.DataFrame(X_cat)\n",
    "dataset.index = X_cat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, X_cat], axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO DOS ATRIBUTOS ENTRE 0 E 1 \n",
    "# normalizar os dados pode ajudar a melhorar a eficiência, a interpretabilidade e a robustez dos modelos de aprendizado de máquina, \n",
    "# especialmente em algoritmos sensíveis à escala das características. \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Convertendo todos os nomes das colunas para strings\n",
    "dataset.columns = dataset.columns.astype(str)\n",
    "dataset_normalizado = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_normalizado.copy()\n",
    "\n",
    "# X = atributos previsores\n",
    "# y = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É preciso ter uma base de dados histórica para que os algoritmos possam treinar.\n",
    "# A partir do treinamento, o algoritmo conseguira fazer classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDAÇÃO CRUZADA define as divisões na base de dados\n",
    "# NÃO É UM ALGORITMO. É UMA FORMA DE SE TRABALHAR E DIMINUIR OS ERROS\n",
    "# k = número de divisões\n",
    "# k é muito usado como 10 (A base é dividida em 10 pedaços)\n",
    "\n",
    "\n",
    "# EXEMPLO K = 4\n",
    "# Serão reaizados 4 treinamentos para evitar erros do algoritmo por um dado ficar em teste.\n",
    "# Assim todos os registros irão participar do treinamento e do teste\n",
    "# Depois será feita uma média dos resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁRVORE DE DECISÃO\n",
    "# O algoritmo vai analisar todos os dados e gerar uma árvore de decisão para classificar os dados de teste\n",
    "# São realizados os cálculos de entropia e ganho de informação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDES NEURAIS ARTIFICIAIS\n",
    "# O objetivo é encontrar os valores de peso de cada categoria\n",
    "# Função Soma faz valor da categoria * peso\n",
    "# Função de ativação vai classificar. O comum é 1 ou 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDES NEURAIS ARTIFICIAIS - REDES MULTICAMADA\n",
    "# O objetivo também é encontrar os melhores pesos.\n",
    "# Encontrar as relações matemáticas\n",
    "# Todos os valores de categoria e os pesos irão se encontrar, criando várias camadas escondidas com uma função soma e uma de ativação.\n",
    "# Depois vai haver uma camada final com uma função soma e uma função de ativação. A função soma irá receber os valores vindo das camadas escondidas com seus pesos.\n",
    "# A função de ativação final é quem realmente vai dar a classificação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(347 + 3) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se os valores de scores.mean() estiverem mais próximos de 1, significa que o modelo está obtendo uma alta precisão média em todas as dobras. \n",
    "# Isso indica que o modelo é capaz de generalizar bem para novos dados e que está capturando padrões importantes nos dados de treinamento.\n",
    "# Se os valores de scores.mean() estiverem mais próximos de 0, significa que o modelo está tendo dificuldade em aprender os padrões nos dados de treinamento e está fazendo previsões aleatórias ou muito ruins.\n",
    "\n",
    "resultados_forest = []\n",
    "resultados_neural = []\n",
    "\n",
    "for i in range(30):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i) # A cada vez que rodar, as divisões serão diferentes. Os resultados também serão.\n",
    "    # É calculada a média de 10 pedaços 30 vezes \n",
    "    # O que está acontecendo: é chamado o algoritmo. É passada a base de dados normalizada com os valores da classe (\"Situação\"). É passada a quant. de intervalos.\n",
    "    # O algoritmo deve aprender a classificar com base na \"Situação\"\n",
    "    random_forest = RandomForestClassifier()\n",
    "    scores = cross_val_score(random_forest, X, y, cv = kfold)\n",
    "    resultados_forest.append(scores.mean())\n",
    "\n",
    "    network = MLPClassifier(hidden_layer_sizes=(175,175)) # São duas camadas ocultas com 175 neurônios cada\n",
    "    scores = cross_val_score(network, X, y, cv = kfold)\n",
    "    resultados_neural.append(scores.mean())\n",
    "\n",
    "resultados_forest = np.array(resultados_forest)\n",
    "resultados_neural = np.array(resultados_neural)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_forest.mean(), resultados_neural.mean()\n",
    "\n",
    "# Quanto maior, mais o algoritmo consegue interpretar bem a base de dados e pode ser usado para analises futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_treinamento, y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = random_forest.predict(X_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_teste, previsoes)\n",
    "cm\n",
    "\n",
    "# Os acertos ficam na diagonal principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(11 + 5 + 29)/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)\n",
    "# As linhas indicam a 'Situação' e as colunas trazem o número de acertos e erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_teste, previsoes))\n",
    "# f1-score é importante quando a quantidade de dados em cada categoria é desbalanceada.\n",
    "# f1 é uma combinação de precision e recall\n",
    "# precision é o quanto o algoritmo tem certeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste[0].reshape(1,-1) # É preciso transformar em matriz para enviar ao algoritmo. Dois colchetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.predict(X_teste[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.feature_importances_\n",
    "# O maior valor indica o parâmetro mais importante para definir a classe/'Situação'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(random_forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome, importancia in zip(dataset.columns, random_forest.feature_importances_):\n",
    "    print(nome, '=', importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristicas = dataset.columns\n",
    "caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancias = random_forest.feature_importances_\n",
    "importancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importancias)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,50))\n",
    "plt.title('Importancia das características')\n",
    "plt.barh(range(len(indices)), importancias[indices], color='b', align = 'center')\n",
    "plt.yticks(range(len(indices)), [caracteristicas[i] for i in indices])\n",
    "plt.xlabel('Importâncias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bases_classificacao.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset, dataset_original, X, y, empresa, scaler], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MELHORANDO A ARVORE DE DECISAO USANDO GRIDSEARCHCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid=parametros)\n",
    "grid_search.fit(X,y)\n",
    "best_params = grid_search.best_params_\n",
    "best_scores = grid_search.best_score_\n",
    "print(best_params, best_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
